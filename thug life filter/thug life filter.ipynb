{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Thug Life Filter Project\n",
    "\n",
    "### Project Overview:\n",
    "This project applies a real-time \"Thug Life\" filter to faces detected from a webcam feed. The filter involves detecting faces using OpenCV's Haar Cascade classifier and overlaying a \"Thug Life\" mask (such as sunglasses) onto the detected faces. The process is done continuously on each frame captured from the webcam.\n",
    "\n",
    "### Steps Involved:\n",
    "\n",
    "1. **Importing Libraries**:\n",
    "   - **OpenCV (cv2)**: Used for real-time computer vision, capturing webcam video, and face detection.\n",
    "   - **NumPy**: For array manipulation.\n",
    "   - **Pillow (PIL.Image)**: Used for handling image manipulation like resizing and pasting the mask on detected faces.\n",
    "\n",
    "2. **Setting Up Resources**:\n",
    "   - **Mask Image**: The image file to be overlaid on the detected face (e.g., \"Thug Life\" sunglasses).\n",
    "   - **Haar Cascade Classifier**: A pre-trained classifier file (`haarcascade_frontalface_default.xml`) for detecting faces in the webcam feed.\n",
    "\n",
    "3. **Face Detection and Mask Application**:\n",
    "   - Faces are detected using the Haar Cascade classifier on the grayscale version of each frame.\n",
    "   - The \"Thug Life\" mask is resized to match the detected face size and is pasted over each detected face, maintaining transparency.\n",
    "   \n",
    "4. **Real-Time Video Capture**:\n",
    "   - The webcam is accessed using OpenCV, and frames are continuously captured.\n",
    "   - The filter is applied frame-by-frame using the `thug_mask` function, and the result is displayed in a window.\n",
    "   - The program listens for the ESC key press to exit the loop and stop capturing.\n",
    "\n",
    "5. **Cleanup**:\n",
    "   - After the loop exits, the webcam is released, and all OpenCV windows are closed.\n",
    "\n",
    "### Key Components:\n",
    "\n",
    "- **Haar Cascade Classifier**: A method for detecting objects in images, used here for face detection.\n",
    "- **Pillow (PIL.Image)**: Used for image manipulation (resizing and pasting the mask onto faces).\n",
    "- **OpenCV**: Handles video capture and display, as well as face detection.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importing Libraries:\n",
    "- **cv2**: This is the OpenCV library for real-time computer vision and image processing tasks.\n",
    "- **numpy**: NumPy is used for array manipulation and numerical operations.\n",
    "- **PIL.Image**: This module from the Pillow library is used for image processing, allowing us to manipulate images.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "import cv2  # OpenCV for real-time computer vision tasks\n",
    "import numpy as np  # NumPy for array manipulation\n",
    "from PIL import Image  # PIL (Pillow) for image processing\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Specifying Paths:\n",
    "- **maskPath**: Path to the image file that will be used as the mask (e.g., a 'Thug Life' sunglasses or any overlay image).\n",
    "- **harcasPath**: Path to the Haar Cascade XML file used for face detection (e.g., \"haarcascade_frontalface_default.xml\").\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Path to the mask image. Replace \"your mask path\" with the actual path to the image file.\n",
    "maskPath = r\"C:\\Users\\asus\\Downloads\\mask.png\"\n",
    "\n",
    "# Path to the Haar Cascade file for face detection. Replace \"your harcas path\" with the actual path to the Haar Cascade XML file.\n",
    "harcasPath = r\"C:\\Users\\asus\\Downloads\\harcass\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading Resources:\n",
    "- **faceCascade**: This line loads the pre-trained Haar Cascade classifier used to detect faces in images.\n",
    "- **mask**: This loads the mask image (like sunglasses or any accessory) that will be placed over the detected faces.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the Haar Cascade classifier for face detection using the path provided.\n",
    "faceCascade = cv2.CascadeClassifier(harcasPath)\n",
    "\n",
    "# Load the mask image that will be placed on the detected faces.\n",
    "mask = Image.open(maskPath)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Function: `thug_mask(image)`\n",
    "- **gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)**: Converts the input image to grayscale since Haar Cascades are optimized for grayscale images.\n",
    "- **faces = faceCascade.detectMultiScale(gray, 2.1)**: Detects faces in the grayscale image. The `2.1` parameter is the scale factor to adjust how much the image size is reduced at each scale.\n",
    "- **background = Image.fromarray(image)**: Converts the NumPy array (original image) to a PIL image for easier manipulation.\n",
    "- **for (x, y, w, h) in faces**: Loops through each detected face, where `x`, `y` are the top-left corner coordinates, and `w`, `h` are the width and height of the detected face.\n",
    "- **resized_mask = mask.resize((w, h), Image.ANTIALIAS)**: Resizes the mask to match the detected face dimensions using anti-aliasing for smoother resizing.\n",
    "- **background.paste(resized_mask, offset, mask=resized_mask)**: Pastes the mask over the detected face, preserving its transparency using the mask parameter.\n",
    "- **return np.asarray(background)**: Converts the modified image back to a NumPy array to display it using OpenCV.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a function to apply the mask on faces detected in the image.\n",
    "def thug_mask(image):\n",
    "    # Convert the input image to grayscale as Haar Cascades work better on grayscale images.\n",
    "    gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "    \n",
    "    # Detect faces in the grayscale image using the Haar Cascade classifier.\n",
    "    faces = faceCascade.detectMultiScale(gray, 2.1)\n",
    "\n",
    "    # Convert the original image from NumPy array to PIL Image.\n",
    "    background = Image.fromarray(image)\n",
    "\n",
    "    # Loop through each face detected and apply the mask.\n",
    "    for (x, y, w, h) in faces:\n",
    "        # Resize the mask to match the size of the detected face.\n",
    "        resized_mask = mask.resize((w, h), Image.ANTIALIAS)\n",
    "        \n",
    "        # Set the offset (position) for where to place the mask on the background image.\n",
    "        offset = (x, y)\n",
    "        \n",
    "        # Paste the resized mask on the face in the background image.\n",
    "        # The mask is applied with its transparency preserved.\n",
    "        background.paste(resized_mask, offset, mask=resized_mask)\n",
    "    \n",
    "    # Return the final image as a NumPy array to display using OpenCV.\n",
    "    return np.asarray(background)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Video Capture:\n",
    "- **cap = cv2.VideoCapture(0)**: This opens the webcam for capturing live video. The `0` refers to the default camera.\n",
    "### Applying the Mask in Real-time:\n",
    "- **ret, frame = cap.read()**: Reads a single frame from the video feed. `ret` is a boolean indicating whether the frame was successfully read.\n",
    "- **if not ret**: If the frame couldn't be captured, an error message is printed, and the loop is stopped.\n",
    "- **cv2.imshow(\"Thug Life Filter\", thug_mask(frame))**: This displays the current frame with the thug mask filter applied in a window titled \"Thug Life Filter\".\n",
    "- **cv2.waitKey(1)**: Waits for 1 millisecond to check if a key is pressed.\n",
    "- **if cv2.waitKey(1) == 27**: If the ESC key (27) is pressed, the loop breaks, and the webcam feed stops.\n",
    "### Cleanup:\n",
    "- **cap.release()**: Releases the webcam so that other applications can use it.\n",
    "- **cv2.destroyAllWindows()**: Closes all OpenCV windows that were opened during the program.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Capture video from the webcam.\n",
    "cap = cv2.VideoCapture(0)\n",
    "# Start an infinite loop to continuously capture frames from the webcam.\n",
    "while True:\n",
    "    # Read a frame from the video feed.\n",
    "    ret, frame = cap.read()\n",
    "    \n",
    "    # If reading the frame failed, print an error message and break the loop.\n",
    "    if not ret:\n",
    "        print(\"Failed to capture image\")\n",
    "        break\n",
    "    \n",
    "    # Try to apply the thug mask filter on the captured frame and display it.\n",
    "    try:\n",
    "        cv2.imshow(\"Thug Life Filter\", thug_mask(frame))\n",
    "    except Exception as e:\n",
    "        print(f\"Error applying filter: {e}\")\n",
    "        break\n",
    "\n",
    "    # Wait for a key press for 1 millisecond, and if the ESC key (27) is pressed, break the loop.\n",
    "    if cv2.waitKey(1) == 27:  # Press ESC to exit\n",
    "        break\n",
    "# Release the webcam and close all OpenCV windows.\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
